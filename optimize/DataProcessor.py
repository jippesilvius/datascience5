#!/usr/bin/env python3

import pandas as pd
import numpy as np
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler, LabelEncoder


class DataProcessor:
    """
    Class that processes the data by doing transformations.
    """
    def __init__(self, input_file_exp, input_file_meta, cols_to_grab, target):
        self.input_file_exp = self.open_exp(input_file_exp)
        self.input_file_meta = self.open_metadata(input_file_meta, cols_to_grab)
        self.target_column = target
        self.merged_df = None


    def open_exp(self, input_file_exp):
        """
        Opens the expression file and put it into a dataframe after setting the index.
        :param input_file_exp:
        :return:
        """
        if not input_file_exp.endswith(".txt.gz"):
            sys.exit(print("Wrong input, must end with .txt.gz"))
        else:
            data_gse = pd.read_csv(input_file_exp, sep='\t', comment='!', quotechar='"',
                                   compression='gzip')
            data_gse.dropna(inplace=True)
            data_gse.set_index("ID_REF", inplace=True)

            return data_gse

    def open_metadata(self, input_file_meta, cols_to_grab):
        """
        Opens the metadata file and puts it into a dataframe
        :param input_file_meta:
        :param cols_to_grab:
        :return:
        """
        lung_pd = pd.read_excel(input_file_meta)
        lung_pd = lung_pd[cols_to_grab]
        lung_pd.rename(columns=lambda x: x.replace('characteristics.tag.', ''), inplace=True)
        lung_pd.dropna(inplace=True)
        # lung_pd['histology'] = lung_pd['histology'].apply(lambda x: x.replace('\xa0', ' ').lower().strip())
        return lung_pd

    def transposing(self):
        """
        Transposing of the expression data
        :return:
        """
        self.input_file_exp = self.input_file_exp.transpose()

    def log_normalize(self):
        """
        Log normalizing the data.
        :return:
        """
        self.input_file_exp = np.log1p(self.input_file_exp)

    def fit_transform(self):
        """
        Scaling the data
        :return:
        """
        scaler = StandardScaler()
        scaled_gse_trans_log = scaler.fit_transform(self.input_file_exp)
        return scaled_gse_trans_log

    # But this is to practice recursion.
    def find_components(self, data, start=2):
        """
        Find the amount of compenents that explain 50% of the total variance.
        :param data:
        :param start:
        :return:
        """
        pca = PCA(n_components=start)
        pca_res = pca.fit_transform(data)
        expl_var_list = pca.explained_variance_ratio_

        if sum(expl_var_list) >= 0.5:
            print(f"N component to reach 50% explained of the variance: {start}")
            print(f"Explained variance list: {expl_var_list}")
            return start, pca, expl_var_list, pca_res
        else:
            start += 1
            return self.find_components(data, start)

    def do_pca(self):
        """
        Do a pca and return findings in a dataframe.
        :return:
        """
        start, pca, expl_var_list, pca_res = self.find_components(self.input_file_exp)
        columns1 = [f"PCA_{i + 1}" for i in range(start)]

        self.input_file_exp = pd.DataFrame(data=pca_res, columns=columns1)

    def merge_df(self):
        """
        merge the data
        :param df1:
        :param df2:
        :return:
        """
        self.merged_df = pd.merge(self.input_file_meta, self.input_file_exp, left_index=True, right_index=True)


    def encode_column(self, df):
        """
        Encode all categorical data.
        :param df:
        :return:
        """
        df_encoded = df.copy()
        encoders = {}
        categorical_cols = df_encoded.select_dtypes(include=['object']).columns.tolist()
        print(categorical_cols)
        for col in categorical_cols:
            if col not in self.target_column:
                encoder = LabelEncoder()
                df_encoded[col] = encoder.fit_transform(df_encoded[col])
                encoders[col] = encoder

        return df_encoded, encoders

    def look_at_encode(self, encoders, column_to_see):
        """
        To look at the values of encoders.
        :param column_to_see:
        :return:
        """
        encoder_look = encoders[column_to_see]

        #generated by chatgpt.
        dict_enc = dict(zip(encoder_look.classes_, range(len(encoder_look.classes_))))

        print(dict_enc)
        return dict_enc

    def pipeline_run(self):
        self.transposing()
        self.log_normalize()
        self.fit_transform()
        self.do_pca()
        self.merge_df()
        encoded_merged_df, encoders = self.encode_column(self.merged_df)
        return encoded_merged_df, encoders