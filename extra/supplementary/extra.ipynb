{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06b3f6f7-6639-44a8-a937-a03c8b7fe471",
   "metadata": {},
   "source": [
    "Checking for normality in a feature\n",
    "P>0.05 feature seems normal within this class\n",
    "P< 0.05 Feature distribution likely not normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e376948c-d923-434f-8307-fe3dc6f0c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "for cls in df['diabetes'].unique():\n",
    "    data = df[df['diabetes'] == cls]['sbp'].dropna()\n",
    "    stat, p = shapiro(data)\n",
    "    print(f\"Class {cls}: Shapiro-Wilk test â†’ W={stat:.3f}, p={p:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb7c7bd-9fe8-4cf7-a293-a149bcdd4746",
   "metadata": {},
   "source": [
    "1. LDA â€” Linear Discriminant Analysis\n",
    "ðŸ”¹ Type\n",
    "\n",
    "Linear classifier\n",
    "\n",
    "Parametric (assumes a specific data distribution)\n",
    "\n",
    "ðŸ”¹ Key idea\n",
    "\n",
    "LDA assumes:\n",
    "\n",
    "Each classâ€™s features are normally distributed,\n",
    "\n",
    "All classes share the same covariance matrix (same â€œshapeâ€ of distribution, just different centers).\n",
    "\n",
    "It finds a linear boundary (a straight line or plane) that best separates classes.\n",
    "\n",
    "ðŸ”¹ Decision boundary\n",
    "\n",
    "Linear â†’ looks like a straight line in 2D, or a hyperplane in higher dimensions.\n",
    "\n",
    "ðŸ”¹ Analogy\n",
    "\n",
    "Itâ€™s like drawing a straight line that separates red and blue points, assuming both groups are â€œblobsâ€ of normally distributed data.\n",
    "\n",
    "ðŸ”¹ Pros\n",
    "\n",
    "Fast, interpretable\n",
    "\n",
    "Works well if data roughly meets the normality & equal covariance assumptions\n",
    "\n",
    "Good for small datasets\n",
    "\n",
    "ðŸ”¹ Cons\n",
    "\n",
    "Not good if boundaries are curved or nonlinear\n",
    "\n",
    "Assumptions may fail in real-world data\n",
    "\n",
    "ðŸ§  2. QDA â€” Quadratic Discriminant Analysis\n",
    "ðŸ”¹ Type\n",
    "\n",
    "Nonlinear classifier\n",
    "\n",
    "Parametric (also assumes normal distributions)\n",
    "\n",
    "ðŸ”¹ Key idea\n",
    "\n",
    "Same as LDA, but allows each class to have its own covariance matrix.\n",
    "\n",
    "That means it can fit curved (quadratic) decision boundaries â€” more flexible.\n",
    "\n",
    "ðŸ”¹ Decision boundary\n",
    "\n",
    "Curved (parabolic, elliptical, etc.)\n",
    "\n",
    "ðŸ”¹ Analogy\n",
    "\n",
    "If your data looks like this:\n",
    "\n",
    "Red   Blue\n",
    "  â—‹     â—\n",
    "   â—‹   â—\n",
    "     â—‹â—\n",
    "   â—‹   â—\n",
    "  â—‹     â—\n",
    "\n",
    "\n",
    "LDA draws a straight line;\n",
    "QDA can draw a curved line that better separates the two.\n",
    "\n",
    "ðŸ”¹ Pros\n",
    "\n",
    "Captures nonlinear relationships\n",
    "\n",
    "More flexible than LDA\n",
    "\n",
    "ðŸ”¹ Cons\n",
    "\n",
    "Needs more data (more parameters to estimate)\n",
    "\n",
    "Can overfit if dataset is small\n",
    "\n",
    "ðŸ§  3. SVM â€” Support Vector Machine\n",
    "ðŸ”¹ Type\n",
    "\n",
    "Linear or nonlinear classifier\n",
    "\n",
    "Non-parametric (no distribution assumptions)\n",
    "\n",
    "ðŸ”¹ Key idea\n",
    "\n",
    "Finds the maximum-margin hyperplane â€” the boundary that separates classes with the largest gap between them.\n",
    "\n",
    "If data arenâ€™t linearly separable, SVM can use a kernel trick (like polynomial or RBF) to project data into a higher-dimensional space where a linear separator exists.\n",
    "\n",
    "ðŸ”¹ Decision boundary\n",
    "\n",
    "Can be linear or nonlinear, depending on kernel.\n",
    "\n",
    "ðŸ”¹ Analogy\n",
    "\n",
    "Imagine two groups of points â€” SVM finds the â€œwidest streetâ€ that separates them and places the decision boundary right in the middle.\n",
    "\n",
    "ðŸ”¹ Pros\n",
    "\n",
    "Works well on complex, nonlinear data\n",
    "\n",
    "Doesnâ€™t need normality assumptions\n",
    "\n",
    "Often high accuracy\n",
    "\n",
    "ðŸ”¹ Cons\n",
    "\n",
    "Harder to interpret\n",
    "\n",
    "Sensitive to parameter tuning (especially kernel and C)\n",
    "\n",
    "Slower on very large datasets\n",
    "\n",
    "ðŸ§  4. k-NN â€” k-Nearest Neighbors\n",
    "ðŸ”¹ Type\n",
    "\n",
    "Non-parametric, instance-based classifier\n",
    "\n",
    "ðŸ”¹ Key idea\n",
    "\n",
    "When predicting a class for a new point:\n",
    "\n",
    "Find the k closest training points (neighbors) in feature space.\n",
    "\n",
    "Assign the majority class among those neighbors.\n",
    "\n",
    "So it makes predictions based purely on proximity.\n",
    "\n",
    "ðŸ”¹ Decision boundary\n",
    "\n",
    "Highly nonlinear, follows the shape of the data.\n",
    "\n",
    "ðŸ”¹ Analogy\n",
    "\n",
    "If you move into a new neighborhood, your class (e.g., â€œdiabetic or notâ€) is predicted based on the majority of your nearest â€œneighborsâ€.\n",
    "\n",
    "ðŸ”¹ Pros\n",
    "\n",
    "Simple and intuitive\n",
    "\n",
    "No training phase (just stores data)\n",
    "\n",
    "Works well if classes are locally well-separated\n",
    "\n",
    "ðŸ”¹ Cons\n",
    "\n",
    "Slow for large datasets (must compare to every training sample)\n",
    "\n",
    "Sensitive to scaling (need to normalize features)\n",
    "\n",
    "Sensitive to noisy or irrelevant features\n",
    "\n",
    "\n",
    "\n",
    "Quick Comparison Summary                                                                                                                       Algorithm Linear?\tAssumptions\tBoundary Type\tStrengths\tWeaknesses\n",
    "\n",
    "LDA\tâœ… Yes\tNormal distribution, equal covariance\tLinear\tFast, interpretable\tPoor with nonlinear data\n",
    "\n",
    "QDA\tâŒ No\tNormal distribution\tQuadratic (curved)\tFlexible\tNeeds more data\n",
    "\n",
    "SVM\tâœ…/âŒ (depends on kernel)\tNone\tLinear or nonlinear\tRobust, powerful\tNeeds tuning\n",
    "\n",
    "k-NN\tâŒ No\tNone\tNonlinear, jagged\tSimple, effective locally\tSlow, sensitive to noise\n",
    "\n",
    ".\n",
    ".\n",
    ".\n",
    "ðŸ§  When to use what\n",
    "\n",
    "Situation\tBest Choice\n",
    "\n",
    "Features roughly normal, linear separation\tLDA\n",
    "\n",
    "Features normal but curved separation\tQDA\n",
    "\n",
    "Complex nonlinear patterns\tSVM (with kernel)\n",
    "\n",
    "Small dataset, few assumptions\tk-NN\n",
    "\n",
    "You want interpretability\tLDA or logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86721fde-dc1b-4cf0-87a1-1426c56a54c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Extra_python import MethodRecommender\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"collegiate_athlete_injury_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc0dd413-0191-43b8-b263-e160c78894d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Athlete_ID  Age  Gender  Height_cm  Weight_kg Position  Training_Intensity  \\\n",
      "0       A001   24  Female        195         99   Center                   2   \n",
      "1       A002   21    Male        192         65  Forward                   8   \n",
      "2       A003   22    Male        163         83    Guard                   8   \n",
      "3       A004   24  Female        192         90    Guard                   1   \n",
      "4       A005   20  Female        173         79   Center                   3   \n",
      "\n",
      "   Training_Hours_Per_Week  Recovery_Days_Per_Week  Match_Count_Per_Week  \\\n",
      "0                       13                       2                     3   \n",
      "1                       14                       1                     3   \n",
      "2                        8                       2                     1   \n",
      "3                       13                       1                     1   \n",
      "4                        9                       1                     2   \n",
      "\n",
      "   Rest_Between_Events_Days  Fatigue_Score  Performance_Score  \\\n",
      "0                         1              1                 99   \n",
      "1                         1              4                 55   \n",
      "2                         3              6                 58   \n",
      "3                         1              7                 82   \n",
      "4                         1              2                 90   \n",
      "\n",
      "   Team_Contribution_Score  Load_Balance_Score  ACL_Risk_Score  \\\n",
      "0                       58                 100               4   \n",
      "1                       63                  83              73   \n",
      "2                       62                 100              62   \n",
      "3                       74                  78              51   \n",
      "4                       51                  83              49   \n",
      "\n",
      "   Injury_Indicator  \n",
      "0                 0  \n",
      "1                 0  \n",
      "2                 0  \n",
      "3                 0  \n",
      "4                 0  \n",
      "Series([], dtype: int64)\n",
      "\n",
      "--- Answer the following questions ---\n",
      "\n",
      "Do you believe the relationship is linear?\n",
      "1. yes\n",
      "2. no\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose a number:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you need high interpretability?\n",
      "1. yes\n",
      "2. no\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose a number:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------\n",
      " Recommended Method: LDA or SVM\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "\n",
    "print(df.isna().sum()[df.isna().sum() > 0])\n",
    "\n",
    "recommend = MethodRecommender(df, \"Gender\")\n",
    "recommend.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e95d0ab-7dd5-4914-9025-66aa5a721f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
